{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection and manipulation\n",
    "\n",
    "- Common shell commands for interactions outside programming environment\n",
    "    - Downloading files from a URL\n",
    "    - Inspect, search, and replace text in files\n",
    "    - Chaining commands together for sequential processing\n",
    "- Shell and IPython (Jupyter notebook)\n",
    "    - Reading shell command output into python variable\n",
    "    - Passing python string back to shell command\n",
    "    - IRS zip code data example: parsing website, extracting URL, and downloading all files\n",
    "- Accessing NBA data\n",
    "    - Understanding GET URL structure\n",
    "    - JSON data format\n",
    "    - Reading JSON data into python\n",
    "    - Creating Pandas data frame\n",
    "\n",
    "## Shell commands\n",
    "\n",
    "### Useful Shell Commands for Text Files\n",
    "\n",
    "- `cat`: prints content of a file\n",
    "- `head`: prints first few lines of a file\n",
    "- `sed`: (stream editor) changes texts\n",
    "- `paste`: pasts text files side-by-side\n",
    "- `cut`: processes columns in delimited text file\n",
    "- `find`: searches file system\n",
    "- `grep`: searches text given regular expression pattern\n",
    "- Many more!\n",
    "\n",
    "### References to learn shell command line\n",
    "\n",
    "- [Software Carpentry Lessons](https://software-carpentry.org/lessons/)\n",
    "- [Unix Power Tools](https://ucsb-primo.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=01UCSB_ALMA51295276690003776&context=L&vid=UCSB&search_scope=default_scope&tab=default_tab&lang=en_US)\n",
    "\n",
    "### File download\n",
    "\n",
    "Sometimes URL of a csv file is directly visible (e.g., Github). In these cases, `wget` is simple but effective. Take https://github.com/fivethirtyeight/data for example. There are many csv files in this repository, and when you browse a file, you see a button named \"raw\".\n",
    "\n",
    "Take the candy ratings data: https://github.com/fivethirtyeight/data/tree/master/candy-power-ranking. Using `wget` it is easy to download the file to course jupyterhub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2018-04-19 05:02:58--  https://raw.githubusercontent.com/fivethirtyeight/data/master/candy-power-ranking/candy-data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.196.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.196.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5205 (5.1K) [text/plain]\n",
      "Saving to: ‘candy-data.csv.1’\n",
      "\n",
      "     0K .....                                                 100% 36.0M=0s\n",
      "\n",
      "2018-04-19 05:02:58 (36.0 MB/s) - ‘candy-data.csv.1’ saved [5205/5205]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget https://raw.githubusercontent.com/fivethirtyeight/data/master/candy-power-ranking/candy-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing file contents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "competitorname,chocolate,fruity,caramel,peanutyalmondy,nougat,crispedricewafer,hard,bar,pluribus,sugarpercent,pricepercent,winpercent\n",
      "100 Grand,1,0,1,0,0,1,0,1,0,.73199999,.86000001,66.971725\n",
      "3 Musketeers,1,0,0,0,1,0,0,1,0,.60399997,.51099998,67.602936\n",
      "One dime,0,0,0,0,0,0,0,0,0,.011,.116,32.261086\n",
      "One quarter,0,0,0,0,0,0,0,0,0,.011,.51099998,46.116505\n",
      "Air Heads,0,1,0,0,0,0,0,0,0,.90600002,.51099998,52.341465\n",
      "Almond Joy,1,0,0,1,0,0,0,1,0,.465,.76700002,50.347546\n",
      "Baby Ruth,1,0,1,1,1,0,0,1,0,.60399997,.76700002,56.914547\n",
      "Boston Baked Beans,0,0,0,1,0,0,0,0,1,.31299999,.51099998,23.417824\n",
      "Candy Corn,0,0,0,0,0,0,0,0,1,.90600002,.32499999,38.010963\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head candy-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "competitorname,chocolate,fruity,caramel,peanutyalmondy,nougat,crispedricewafer,hard,bar,pluribus,sugarpercent,pricepercent,winpercent\r\n",
      "100 Grand,1,0,1,0,0,1,0,1,0,.73199999,.86000001,66.971725\r\n",
      "3 Musketeers,1,0,0,0,1,0,0,1,0,.60399997,.51099998,67.602936\r\n",
      "One dime,0,0,0,0,0,0,0,0,0,.011,.116,32.261086\r\n",
      "One quarter,0,0,0,0,0,0,0,0,0,.011,.51099998,46.116505\r\n",
      "Air Heads,0,1,0,0,0,0,0,0,0,.90600002,.51099998,52.341465\r\n",
      "Almond Joy,1,0,0,1,0,0,0,1,0,.465,.76700002,50.347546\r\n",
      "Baby Ruth,1,0,1,1,1,0,0,1,0,.60399997,.76700002,56.914547\r\n",
      "Boston Baked Beans,0,0,0,1,0,0,0,0,1,.31299999,.51099998,23.417824\r\n",
      "Candy Corn,0,0,0,0,0,0,0,0,1,.90600002,.32499999,38.010963\r\n"
     ]
    }
   ],
   "source": [
    "! head candy-data.csv ## also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "competitorname,chocolate,fruity,caramel,peanutyalmondy,nougat,crispedricewafer,hard,bar,pluribus,sugarpercent,pricepercent,winpercent\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 1 candy-data.csv  ## first line is the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 candy-data.csv\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l candy-data.csv      ## counts lines in text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "competitorname,fruity\r\n",
      "100 Grand,0\r\n",
      "3 Musketeers,0\r\n",
      "One dime,0\r\n",
      "One quarter,0\r\n",
      "Air Heads,1\r\n",
      "Almond Joy,0\r\n",
      "Baby Ruth,0\r\n",
      "Boston Baked Beans,0\r\n",
      "Candy Corn,0\r\n",
      "Caramel Apple Pops,1\r\n",
      "Charleston Chew,0\r\n",
      "Chewey Lemonhead Fruit Mix,1\r\n",
      "Chiclets,1\r\n",
      "Dots,1\r\n",
      "Dum Dums,1\r\n",
      "Fruit Chews,1\r\n",
      "Fun Dip,1\r\n",
      "Gobstopper,1\r\n",
      "Haribo Gold Bears,1\r\n",
      "Haribo Happy Cola,0\r\n",
      "Haribo Sour Bears,1\r\n",
      "Haribo Twin Snakes,1\r\n",
      "HersheyÕs Kisses,0\r\n",
      "HersheyÕs Krackel,0\r\n",
      "HersheyÕs Milk Chocolate,0\r\n",
      "HersheyÕs Special Dark,0\r\n",
      "Jawbusters,1\r\n",
      "Junior Mints,0\r\n",
      "Kit Kat,0\r\n",
      "Laffy Taffy,1\r\n",
      "Lemonhead,1\r\n",
      "Lifesavers big ring gummies,1\r\n",
      "Peanut butter M&MÕs,0\r\n",
      "M&MÕs,0\r\n",
      "Mike & Ike,1\r\n",
      "Milk Duds,0\r\n",
      "Milky Way,0\r\n",
      "Milky Way Midnight,0\r\n",
      "Milky Way Simply Caramel,0\r\n",
      "Mounds,0\r\n",
      "Mr Good Bar,0\r\n",
      "Nerds,1\r\n",
      "Nestle Butterfinger,0\r\n",
      "Nestle Crunch,0\r\n",
      "Nik L Nip,1\r\n",
      "Now & Later,1\r\n",
      "Payday,0\r\n",
      "Peanut M&Ms,0\r\n",
      "Pixie Sticks,0\r\n",
      "Pop Rocks,1\r\n",
      "Red vines,1\r\n",
      "ReeseÕs Miniatures,0\r\n",
      "ReeseÕs Peanut Butter cup,0\r\n",
      "ReeseÕs pieces,0\r\n",
      "ReeseÕs stuffed with pieces,0\r\n",
      "Ring pop,1\r\n",
      "Rolo,0\r\n",
      "Root Beer Barrels,0\r\n",
      "Runts,1\r\n",
      "Sixlets,0\r\n",
      "Skittles original,1\r\n",
      "Skittles wildberry,1\r\n",
      "Nestle Smarties,0\r\n",
      "Smarties candy,1\r\n",
      "Snickers,0\r\n",
      "Snickers Crisper,0\r\n",
      "Sour Patch Kids,1\r\n",
      "Sour Patch Tricksters,1\r\n",
      "Starburst,1\r\n",
      "Strawberry bon bons,1\r\n",
      "Sugar Babies,0\r\n",
      "Sugar Daddy,0\r\n",
      "Super Bubble,1\r\n",
      "Swedish Fish,1\r\n",
      "Tootsie Pop,1\r\n",
      "Tootsie Roll Juniors,0\r\n",
      "Tootsie Roll Midgies,0\r\n",
      "Tootsie Roll Snack Bars,0\r\n",
      "Trolli Sour Bites,1\r\n",
      "Twix,0\r\n",
      "Twizzlers,1\r\n",
      "Warheads,1\r\n",
      "WelchÕs Fruit Snacks,1\r\n",
      "WertherÕs Original Caramel,0\r\n",
      "Whoppers,0\r\n"
     ]
    }
   ],
   "source": [
    "! cut -d',' -f1,3 candy-data.csv    ## prints columns of delimited text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tootsie Pop,1,1,0,0,0,0,1,0,0,.60399997,.32499999,48.982651\r\n",
      "Tootsie Roll Juniors,1,0,0,0,0,0,0,0,0,.31299999,.51099998,43.068897\r\n",
      "Tootsie Roll Midgies,1,0,0,0,0,0,0,0,1,.17399999,.011,45.736748\r\n",
      "Tootsie Roll Snack Bars,1,0,0,0,0,0,0,1,0,.465,.32499999,49.653503\r\n"
     ]
    }
   ],
   "source": [
    "! grep 'Tootsie' candy-data.csv      ## finds lines with pattern (regular expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining commands togeter\n",
    "\n",
    "The power of command lines is unleashed when you chain commands together. You can achieve this by using \"pipes\". \n",
    "Many commands in the shell sends output to what is called \"stdout\" (essentially printing to screen). What enables pipes is to receive input from \"stdin\" (standard input).\n",
    "\n",
    "Hence, we can make commands such as the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n1 candy-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n1 candy-data.csv | sed 's/,/\\n/g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n1 candy-data.csv | sed 's/,/\\n/g' | sed 's/chocolate/CHOCOLATE/g'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text file search and manipulation\n",
    "\n",
    "Comands like `grep`, `sed` and `awk` enable on-the-fly text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget -q -O - https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi \\\n",
    "#     | grep 'zipcode.zip' \\\n",
    "#     | sed 's/<a data/\\n<a data/g' \\\n",
    "#     | grep -Po '(?<=href=\")[^\"]*(?=\")'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shell and Jupyter\n",
    "\n",
    "Shell and Jupyter can be used together, and this becomes even more interesting.\n",
    "\n",
    "We can do things such as download all files with `zipcode.zip` file ending by first grabbing all such file names from the html page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = !wget -q -O - https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi | grep 'zipcode.zip' | sed 's/<a data/\\n<a data/g' | grep -Po '(?<=href=\")[^\"]*(?=\")'\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing Jupyter variables to shell\n",
    "\n",
    "We can write a python loop to download each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files[:3]:\n",
    "    ! wget {f}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciphering the NBA stats API\n",
    "\n",
    "NBA provides a nice website for all data related to the tornament: [http://stat.nba.com](http://stat.nba.com). For example, in order to navigate to the shooting records for Stephen Curry, you navigate their menus to get to here:\n",
    "\n",
    "> [http://stats.nba.com/player/201939/shooting/?Season=2016-17&SeasonType=Regular%20Season](http://stats.nba.com/player/201939/shooting/?Season=2016-17&SeasonType=Regular%20Season)\n",
    "\n",
    "Here, we see some information related to our choices:\n",
    "- Season: 2016-17\n",
    "- SeasonType: Regular Season ([%20 is character code for space](https://en.wikipedia.org/wiki/Percent-encoding#Character_data))\n",
    "- Player: 201939 (less obvious)\n",
    "\n",
    "This type of URL is using a [GET method](https://www.w3schools.com/tags/ref_httpmethods.asp). When your URLs are very long, it is usually passing a series of variables and values to the web page. There are tools such as this [online URL parser](https://www.freeformatter.com/url-parser-query-string-splitter.html). Try passing in the URL.\n",
    "\n",
    "Knowledge of how web sites work is useful for data science since there is so much interaction through the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useragent = \"\\\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9\\\"\"\n",
    "playerurl = \"\\\"http://stats.nba.com/stats/commonallplayers?LeagueID=00&Season=2015-16&IsOnlyCurrentSeason=0\\\"\"\n",
    "json_str = !wget -q -O - --user-agent={useragent} {playerurl}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above defines a url to download data from. Also, it defines an argument for what is called a User Agent. User agent allows you to mimic any browser. This is useful since websites can return different content depending on the browser users are on.\n",
    "\n",
    "In the case of NBA data, they block programatic scraping of websites by simple use of `wget`. However, by passing in the user agent string, we pretend that our connection is a user using a Mozilla-type browser on OS X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what is called the json format (Javascript object notation) and is becoming one of the widely used standards in data formats.\n",
    "\n",
    "In fact, Jupyter notebooks are entirely in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head 03-Data-collection-and-manipulation.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json format is very similar to Python dictionary: i.e., key and values.\n",
    "\n",
    "There are built-in libraries to work with json files formats. We read the output of `wget` command into a python variable: `json_str`. Now, we can parse that string with the `json` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.loads(json_str[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['resultSets'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['resultSets'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "h = data['resultSets'][0]['headers']\n",
    "d = data['resultSets'][0]['rowSet']\n",
    "players = pd.DataFrame(d, columns=h)\n",
    "players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What other data can we download using these types of URLS? It turns out that NBA does not publish (I wasn't able to find one) an official documentation, but people have come up with a [community documentation](https://github.com/seemethere/nba_py/wiki/stats.nba.com-Endpoint-Documentation).\n",
    "\n",
    "Let's work with the [shot chart](https://github.com/seemethere/nba_py/wiki/stats.nba.com-Endpoint-Documentation#shotchartdetail). The site kindly tells me [which parameters are required if none is passed](http://stats.nba.com/stats/shotchartdetail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "params = {'LeagueID':'00'}\n",
    "teamurl = 'http://stats.nba.com/stats/commonTeamYears?' + urlencode(params)\n",
    "!wget -q -O - --user-agent={useragent} {teamurl}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what a general request looks like, we can create a function to make our requests simpler.\n",
    "\n",
    "The function will do the following:\n",
    "1. Set User Agent\n",
    "1. Set base URL with appropriate end point\n",
    "1. Set parameters required for query\n",
    "1. Read JSON string into python variable\n",
    "1. Parse JSON string into python object\n",
    "1. Convert the objects into pandas a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nba_data(endpt, params, return_url=False):\n",
    "\n",
    "    ## endpt: https://github.com/seemethere/nba_py/wiki/stats.nba.com-Endpoint-Documentation\n",
    "    ## params: dictionary of parameters: i.e., {'LeagueID':'00'}\n",
    "    from pandas import DataFrame\n",
    "    from urllib.parse import urlencode\n",
    "    import json\n",
    "    \n",
    "    useragent = \"\\\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9\\\"\"\n",
    "\n",
    "    dataurl = \"\\\"\" + \"http://stats.nba.com/stats/\" + endpt + \"?\" + urlencode(params) + \"\\\"\"\n",
    "    \n",
    "    # for debugging: just return the url\n",
    "    if return_url:\n",
    "        return(dataurl)\n",
    "    \n",
    "    jsonstr = !wget -q -O - --user-agent={useragent} {dataurl}\n",
    "    \n",
    "    data = json.loads(jsonstr[0])\n",
    "    \n",
    "    h = data['resultSets'][0]['headers']\n",
    "    d = data['resultSets'][0]['rowSet']\n",
    "    \n",
    "    return(DataFrame(d, columns=h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what URL string is returned, set `return_url=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'LeagueID':'00'}\n",
    "get_nba_data('commonTeamYears', params, return_url=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'LeagueID':'00'}\n",
    "teamdata = get_nba_data('commonTeamYears', params)\n",
    "teamdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'LeagueID':'00', 'Season': '2016-17', 'IsOnlyCurrentSeason': '0'}\n",
    "plyrdata = get_nba_data('commonallplayers', params)\n",
    "plyrdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can get the shot chart detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'PlayerID':'201935',\n",
    "          'PlayerPosition':'',\n",
    "          'Season':'2016-17',\n",
    "          'ContextMeasure':'FGA',\n",
    "          'DateFrom':'',\n",
    "          'DateTo':'',\n",
    "          'GameID':'',\n",
    "          'GameSegment':'',\n",
    "          'LastNGames':'0',\n",
    "          'LeagueID':'00',\n",
    "          'Location':'',\n",
    "          'Month':'0',\n",
    "          'OpponentTeamID':'0',\n",
    "          'Outcome':'',\n",
    "          'Period':'0',\n",
    "          'Position':'',\n",
    "          'RookieYear':'',\n",
    "          'SeasonSegment':'',\n",
    "          'SeasonType':'Regular Season',\n",
    "          'TeamID':'0',\n",
    "          'VsConference':'',\n",
    "          'VsDivision':''}\n",
    "\n",
    "shotdata = get_nba_data('shotchartdetail', params)\n",
    "shotdata.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
